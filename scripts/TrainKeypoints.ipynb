{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "cv2.setNumThreads(1)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dshdf5pose import Hdf5PoseDataset\n",
    "import datatransformation\n",
    "import neuralnets.models as models\n",
    "import vis\n",
    "import utils\n",
    "import train\n",
    "from datasets.infinitelyrepeatinginterleaveddatasets import InfinitelyRepeatingInterleavedDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as tf\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset, ConcatDataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputsize = 129\n",
    "datadir = os.environ['DATADIR']\n",
    "\n",
    "augment = [\n",
    "    datatransformation.ApplyRoiRandomized(),\n",
    "    datatransformation.Rescale((inputsize,inputsize)),\n",
    "    datatransformation.AdaptiveBrightnessContrastDistortion(),\n",
    "    datatransformation.Flip(),\n",
    "]\n",
    "testpreprocess = [\n",
    "    datatransformation.ApplyRoi(),\n",
    "    datatransformation.Rescale(inputsize+1),\n",
    "    datatransformation.CenterCrop(inputsize),\n",
    "]\n",
    "normalize_and_tensor = [\n",
    "    datatransformation.Normalize(monochrome=True),\n",
    "    datatransformation.ToTensor()\n",
    "]\n",
    "\n",
    "ds_train_aflw = Hdf5PoseDataset(join(datadir,'aflw2k.h5'), shuffle=True, subset=slice(400,None), transform=transforms.Compose([\n",
    "    datatransformation.InjectPt3d68Enable(),\n",
    "    datatransformation.InjectPoseEnable(),\n",
    "    *augment,\n",
    "    *normalize_and_tensor\n",
    "]))\n",
    "\n",
    "ds_full_300wlp = Hdf5PoseDataset(join(datadir,'300wlp.h5'), shuffle=True, transform=transforms.Compose([\n",
    "    datatransformation.InjectPt3d68Enable(),\n",
    "    datatransformation.InjectPoseEnable(),\n",
    "    *augment,\n",
    "    *normalize_and_tensor\n",
    "]))\n",
    "\n",
    "ds_full_ytfaces = Hdf5PoseDataset(join(datadir,'ytfaces.h5'), shuffle=True, transform=transforms.Compose([\n",
    "    datatransformation.InjectPoseEnable(),\n",
    "    datatransformation.InjectPt3d68Enable(),\n",
    "    *augment,\n",
    "    *normalize_and_tensor\n",
    "]))\n",
    "\n",
    "\n",
    "# ds_test_biwi = Hdf5PoseDataset(join(datadir,'biwi.h5'), shuffle=True, subset=None, transform=transforms.Compose([\n",
    "#     datatransformation.InjectZeroKeypoints3d(),\n",
    "#     datatransformation.InjectPoseEnable(),\n",
    "#     *testpreprocess,\n",
    "#     *normalize_and_tensor\n",
    "# ]))\n",
    "\n",
    "ds_test_aflw = Hdf5PoseDataset(join(datadir,'aflw2k.h5'), shuffle=False, subset=slice(400), transform=transforms.Compose([\n",
    "    datatransformation.InjectPt3d68Enable(),\n",
    "    datatransformation.InjectPoseEnable(),\n",
    "    *testpreprocess,\n",
    "    *normalize_and_tensor\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Train ds sizes: \", [len(ds) for ds in [ds_train_aflw, ds_full_300wlp, ds_full_ytfaces]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test_aflw\n",
    "\n",
    "#ds_train = ds_train_aflw\n",
    "ds_train = InfinitelyRepeatingInterleavedDatasets(\n",
    "    32*1024, \n",
    "    [ds_train_aflw, ds_full_ytfaces, ds_full_300wlp], \n",
    "    [1., 10., 10.])\n",
    "\n",
    "train_loader = datatransformation.PostprocessingDataLoader(ds_train, \n",
    "                          batch_size=128,\n",
    "                          shuffle=False, \n",
    "                          num_workers=5,\n",
    "                          postprocess = transforms.Compose([\n",
    "                                datatransformation.BlurNoiseDistortion(),\n",
    "                          ]))\n",
    "test_loader = DataLoader(ds_test, \n",
    "                          batch_size=128,\n",
    "                          shuffle=False, \n",
    "                          num_workers=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def drawfunc(ax, sample):\n",
    "    vis.draw_dataset_sample(ax, vis.unnormalize_sample_to_numpy(sample), label=False)\n",
    "%matplotlib notebook\n",
    "vis.matplotlib_plot_iterable(ds_train, drawfunc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "vis.matplotlib_plot_iterable(ds_test, drawfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = models.NetworkWithPointHead()\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = net.parameters()\n",
    "backbone_params_1 = net.convnet.backbone[:9].parameters()\n",
    "backbone_params_2 = net.convnet.backbone[9:11].parameters()\n",
    "backbone_params_3 = net.convnet.backbone[14:].parameters()\n",
    "untrained_params = list(set(all_params) - set(backbone_params_1) - set(backbone_params_2) - set(backbone_params_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pyplot.ioff()\n",
    "\n",
    "#optimizer = optim.Adam(net.parameters(), lr=1.e-3)\n",
    "optimizer = optim.Adam([\n",
    "    {'params': backbone_params_1, 'lr': 1e-6},\n",
    "    {'params': backbone_params_2, 'lr': 1e-4},\n",
    "    {'params': backbone_params_3, 'lr': 1e-3},\n",
    "    {'params': untrained_params}],\n",
    "    lr=1.e-3)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [40, 80], gamma=0.33)\n",
    "\n",
    "network_filename = None\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "criterions = [\n",
    "    train.MixedParameterKeypointLoss(n_epochs),\n",
    "    #train.AllParameterLoss(),\n",
    "    #train.Points3dLoss(),\n",
    "    train.BoxLoss(),\n",
    "    train.QuaternionNormalizationRegularization(),\n",
    "]\n",
    "critweights = np.array([1., 0.1, 1.e-5 ])\n",
    "\n",
    "train.run_the_training(n_epochs,\n",
    "                      optimizer,\n",
    "                      net,\n",
    "                      train_loader,\n",
    "                      test_loader,\n",
    "                      criterions,\n",
    "                      critweights,\n",
    "                      2,\n",
    "                      join('..','model_files'),\n",
    "                      network_filename,\n",
    "                      other_metrics = [\n",
    "                        train.QuatPoseLoss2(),\n",
    "                        train.CoordPoseLoss(),\n",
    "                        train.ShapeParameterLoss(),\n",
    "                        train.Points3dLoss(),\n",
    "                      ],\n",
    "                      scheduler = scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
